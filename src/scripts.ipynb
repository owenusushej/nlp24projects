{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599b784e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.005529,
     "end_time": "2024-04-14T12:59:31.608353",
     "exception": false,
     "start_time": "2024-04-14T12:59:31.602824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Created by yunsuxiaozi 2024/4/14\n",
    "\n",
    "### 比赛链接如下: https://www.biendata.xyz/competition/ind_kdd_2024/\n",
    "\n",
    "### 这是我第一次参加KDD_cup,记录一下.本次比赛应该会用到知识图谱的相关知识,我这里给一个数据挖掘方面的baseline,目前分数还算不错."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e374c8",
   "metadata": {
    "papermill": {
     "duration": 0.004331,
     "end_time": "2024-04-14T12:59:31.617712",
     "exception": false,
     "start_time": "2024-04-14T12:59:31.613381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2fbc4a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:38:58.156046Z",
     "start_time": "2024-05-31T07:38:58.140398Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-14T12:59:31.629805Z",
     "iopub.status.busy": "2024-04-14T12:59:31.629156Z",
     "iopub.status.idle": "2024-04-14T12:59:35.525995Z",
     "shell.execute_reply": "2024-04-14T12:59:35.524676Z"
    },
    "papermill": {
     "duration": 3.906376,
     "end_time": "2024-04-14T12:59:35.528957",
     "exception": false,
     "start_time": "2024-04-14T12:59:31.622581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#necessary\n",
    "import pandas as pd#导入csv文件的库\n",
    "import numpy as np#进行矩阵运算的库\n",
    "import json#用于读取和写入json数据格式\n",
    "import string\n",
    "\n",
    "#model lgb分类模型,日志评估,早停防止过拟合\n",
    "from  lightgbm import LGBMClassifier,log_evaluation,early_stopping\n",
    "from nltk import word_tokenize\n",
    "import torch\n",
    "#metric\n",
    "from sklearn.metrics import roc_auc_score#导入roc_auc曲线\n",
    "#KFold是直接分成k折,StratifiedKFold还要考虑每种类别的占比\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 图神经网络\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import networkx as nx\n",
    "import traceback\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2451b23a",
   "metadata": {
    "papermill": {
     "duration": 0.004596,
     "end_time": "2024-04-14T12:59:35.538428",
     "exception": false,
     "start_time": "2024-04-14T12:59:35.533832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 设置相关的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a90213c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:38:58.428684Z",
     "start_time": "2024-05-31T07:38:58.405409Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-14T12:59:35.551070Z",
     "iopub.status.busy": "2024-04-14T12:59:35.549735Z",
     "iopub.status.idle": "2024-04-14T12:59:35.557369Z",
     "shell.execute_reply": "2024-04-14T12:59:35.556175Z"
    },
    "papermill": {
     "duration": 0.016468,
     "end_time": "2024-04-14T12:59:35.560053",
     "exception": false,
     "start_time": "2024-04-14T12:59:35.543585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#config\n",
    "class Config():\n",
    "    seed=2024#随机种子\n",
    "    num_folds=10#K折交叉验证\n",
    "    TARGET_NAME ='label'#标签\n",
    "import random#提供了一些用于生成随机数的函数\n",
    "#设置随机种子,保证模型可以复现\n",
    "def seed_everything(seed):\n",
    "    np.random.seed(seed)#numpy的随机种子\n",
    "    random.seed(seed)#python内置的随机种子\n",
    "seed_everything(Config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12332a6f",
   "metadata": {
    "papermill": {
     "duration": 0.004502,
     "end_time": "2024-04-14T12:59:35.569434",
     "exception": false,
     "start_time": "2024-04-14T12:59:35.564932",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 导入相关的数据集,我这里是将数据放在Kaggle上."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a54f4c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:39:17.465559Z",
     "start_time": "2024-05-31T07:38:58.440176Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-14T12:59:35.583422Z",
     "iopub.status.busy": "2024-04-14T12:59:35.582977Z",
     "iopub.status.idle": "2024-04-14T13:00:07.938280Z",
     "shell.execute_reply": "2024-04-14T13:00:07.936950Z"
    },
    "papermill": {
     "duration": 32.364963,
     "end_time": "2024-04-14T13:00:07.941386",
     "exception": false,
     "start_time": "2024-04-14T12:59:35.576423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path='./data/'\n",
    "#sample: Iki037dt dict_keys(['name', 'normal_data', 'outliers'])\n",
    "with open(path+\"train/train_author.json\", encoding='utf-8') as f:\n",
    "    train_author=json.load(f)\n",
    "#sample : 6IsfnuWU dict_keys(['id', 'title', 'authors', 'abstract', 'keywords', 'venue', 'year'])   \n",
    "with open(path+\"train/pid_to_info_all.json\", encoding='utf-8') as f:\n",
    "    pid_to_info=json.load(f)\n",
    "#efQ8FQ1i dict_keys(['name', 'papers'])\n",
    "with open(path+\"ind_valid/ind_valid_author.json\", encoding='utf-8') as f:\n",
    "    valid_author=json.load(f)\n",
    "\n",
    "with open(path+\"ind_valid/ind_valid_author_submit.json\" ,encoding='utf-8') as f:\n",
    "    submission=json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440a020",
   "metadata": {
    "papermill": {
     "duration": 0.004549,
     "end_time": "2024-04-14T13:00:07.950952",
     "exception": false,
     "start_time": "2024-04-14T13:00:07.946403",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 这里做了简单的特征工程."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "552bff3e01a4bbfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:39:17.496506Z",
     "start_time": "2024-05-31T07:39:17.470382Z"
    }
   },
   "outputs": [],
   "source": [
    "puncs = '[!“”\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~—～’]+'\n",
    "stopwords = ['at', 'based', 'in', 'of', 'for', 'on', 'and', 'to', 'an', 'using', 'with',\n",
    "                    'the', 'by', 'we', 'be', 'is', 'are', 'can']\n",
    "# self.stopwords_extend = ['university', 'univ', 'china', 'department', 'dept', 'laboratory', 'lab',\n",
    "#                          'school', 'al', 'et', 'institute', 'inst', 'college', 'chinese', 'beijing',\n",
    "#                          'journal', 'science', 'international']\n",
    "stopwords_extend = ['university', 'univ', 'china', 'department', 'dept', 'laboratory', 'lab',\n",
    "                            'school', 'al', 'et', 'institute', 'inst', 'college', 'chinese', 'beijing',\n",
    "                            'journal', 'science', 'international', 'key', 'sciences', 'research',\n",
    "                            'academy', 'state', 'center']\n",
    "\n",
    "stopwords_check = ['a', 'was', 'were', 'that', '2', 'key', '1', 'technology', '0', 'sciences', 'as',\n",
    "                            'from', 'r', '3', 'academy', 'this', 'nanjing', 'shanghai', 'state', 's', 'research',\n",
    "                        'p', 'results', 'peoples', '4', 'which', '5', 'high', 'materials', 'study', 'control',\n",
    "                        'method', 'group', 'c', 'between', 'or', 'it', 'than', 'analysis', 'system',  'sci',\n",
    "                        'two', '6', 'has', 'h', 'after', 'different', 'n', 'national', 'japan', 'have', 'cell',\n",
    "                        'time', 'zhejiang', 'used', 'data', 'these']\n",
    "\n",
    "stopwords_custom = stopwords + stopwords_extend + stopwords_check\n",
    "# 删除停用词\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords_custom)\n",
    "    text = text.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c8261d90af4e2c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:39:26.922982Z",
     "start_time": "2024-05-31T07:39:17.501706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_ENDPOINT=https://hf-mirror.com\n"
     ]
    }
   ],
   "source": [
    "%env HF_ENDPOINT=https://hf-mirror.com\n",
    "# 加载BERT模型和分词器\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63d99115b88ea215",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-31T07:39:26.939247Z",
     "start_time": "2024-05-31T07:39:26.922982Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_cls_embedding(text, model=model, tokenizer=tokenizer):\n",
    "   \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    inputs = {name: tensor.to(device) for name, tensor in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "    if device.type == \"cuda\":\n",
    "        cls_embedding = cls_embedding.cpu()\n",
    "    return cls_embedding.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ea311bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取图关系网络\n",
    "coauthor_graph = nx.Graph()\n",
    "for author_id, author_info in train_author.items():\n",
    "    papers = author_info['normal_data']\n",
    "    for paper_id in papers:\n",
    "        authors = pid_to_info[paper_id]['authors']\n",
    "        for coauthor in authors:\n",
    "            if coauthor['name'] != author_info['name']:\n",
    "                coauthor_graph.add_edge(author_info['name'], coauthor['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "097cd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthor_nodes = list(coauthor_graph.nodes())\n",
    "num_nodes = len(coauthor_nodes)\n",
    "num_edges = coauthor_graph.number_of_edges()\n",
    "\n",
    "node_degrees = dict(coauthor_graph.degree())\n",
    "\n",
    "node_features = torch.tensor([node_degrees[node] for node in coauthor_nodes], dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "node_to_index = {node: index for index, node in enumerate(coauthor_nodes)}\n",
    "\n",
    "edges = [(node_to_index[edge[0]], node_to_index[edge[1]]) for edge in coauthor_graph.edges()]\n",
    "\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "data = Data(x=node_features, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58ed9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 初始化GNN模型\n",
    "input_dim = 1\n",
    "hidden_dim = 64\n",
    "output_dim = 32\n",
    "gnn_model = GNN(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af325681",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 将模型移到GPU\n",
    "gnn_model = gnn_model.to(device)\n",
    "\n",
    "# 设置模型为评估模式（这一步对于推理非常重要，可以关闭dropout等训练时的特性）\n",
    "gnn_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # 确保data也在GPU上\n",
    "    data = data.to(device)\n",
    "    graph_embeddings = gnn_model(data)\n",
    "\n",
    "# 将图特征映射回作者，这里假设不需要在GPU上进行此操作，直接转为numpy用于后续处理\n",
    "author_embeddings = {}\n",
    "for index, author_name in enumerate(coauthor_nodes):\n",
    "    author_embeddings[author_name] = graph_embeddings[index].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e5e31cea",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-31T07:39:26.944451Z"
    },
    "execution": {
     "iopub.execute_input": "2024-04-14T13:00:07.962527Z",
     "iopub.status.busy": "2024-04-14T13:00:07.962053Z",
     "iopub.status.idle": "2024-04-14T13:00:09.317361Z",
     "shell.execute_reply": "2024-04-14T13:00:09.316054Z"
    },
    "jupyter": {
     "is_executing": true
    },
    "papermill": {
     "duration": 1.364457,
     "end_time": "2024-04-14T13:00:09.320169",
     "exception": false,
     "start_time": "2024-04-14T13:00:07.955712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: object of type 'NoneType' has no len()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_12598/958863425.py\", line 47, in <module>\n",
      "    , len(feat['venue']), publication_age, venue_freq[venue]]\n",
      "TypeError: object of type 'NoneType' has no len()\n"
     ]
    }
   ],
   "source": [
    "# 假设当前年份为基准年份，用于计算Publication Age\n",
    "CURRENT_YEAR = 2024\n",
    "\n",
    "# 初始化venue频次字典\n",
    "venue_freq = {}\n",
    "\n",
    "basic_feats = []\n",
    "bert_feats = []\n",
    "graph_feats = []\n",
    "labels = []\n",
    "for id, person_info in train_author.items():\n",
    "    for text_id, label in [(tid, 1) for tid in person_info['normal_data']] + [(tid, 0) for tid in person_info['outliers']]:\n",
    "        feat = pid_to_info[text_id]\n",
    "        # ['title', 'abstract', 'keywords', 'authors', 'venue', 'year']\n",
    "        # Skip if feat is None or any required field in feat is None\n",
    "        try:\n",
    "            # 时间特征更改为距今多久\n",
    "            year_str = feat.get('year', '')\n",
    "            if year_str:\n",
    "                publication_age = CURRENT_YEAR - int(year_str)\n",
    "            else:\n",
    "                publication_age = CURRENT_YEAR - 2000\n",
    "                \n",
    "            # 地点特征改为共出现多少次这个机构\n",
    "            venue = feat['venue']\n",
    "            if venue in venue_freq:\n",
    "                venue_freq[venue] += 1\n",
    "            else:\n",
    "                venue_freq[venue] = 1\n",
    "\n",
    "            # 计算bert对于title和abstract的embedding\n",
    "            title_embedding = get_cls_embedding(feat['title'])\n",
    "            abstract_embedding = get_cls_embedding(feat['abstract'])\n",
    "\n",
    "            bert_features = np.concatenate([title_embedding, abstract_embedding])\n",
    "            \n",
    "            # 添加图特征\n",
    "            authors = feat['authors']\n",
    "            embeddings = [author_embeddings[author['name']] for author in authors if author['name'] in author_embeddings]\n",
    "            if embeddings:\n",
    "                graph_features = np.mean(embeddings, axis=0)\n",
    "            else:\n",
    "                graph_features = np.zeros(32)\n",
    "\n",
    "            basic_feats.append(\n",
    "                [len(feat['title']), len(feat['abstract']), len(feat['keywords']), len(feat['authors'])\n",
    "                 , len(feat['venue']), publication_age, venue_freq[venue]]\n",
    "            )\n",
    "            bert_feats.append(bert_features)\n",
    "            graph_feats.append(graph_features)\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred:\", e)  # 打印异常信息\n",
    "            traceback.print_exc()  # 打印详细的异常信息\n",
    "            basic_feats.append(\n",
    "                [len(feat['title']), len(feat['abstract']), len(feat['keywords']), len(feat['authors'])\n",
    "                 , 0, 24, 0]\n",
    "            )\n",
    "            bert_feats.append([0] * (2 * 768)) \n",
    "            graph_feats.append(np.zeros(32))\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ae8038dd487c799c",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "basic_feats = np.array(basic_feats)\n",
    "bert_feats = np.array(bert_feats)\n",
    "graph_feats = np.array(graph_feats)\n",
    "train_feats = np.concatenate([basic_feats, bert_feats,graph_feats], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae61aca71312fa5d",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_feats.shape:(148309, 1575),labels.shape:(148309,)\n",
      "np.mean(labels):0.8834527911320283\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1566</th>\n",
       "      <th>1567</th>\n",
       "      <th>1568</th>\n",
       "      <th>1569</th>\n",
       "      <th>1570</th>\n",
       "      <th>1571</th>\n",
       "      <th>1572</th>\n",
       "      <th>1573</th>\n",
       "      <th>1574</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.470130</td>\n",
       "      <td>-0.494594</td>\n",
       "      <td>-0.253409</td>\n",
       "      <td>...</td>\n",
       "      <td>172.577667</td>\n",
       "      <td>917.606812</td>\n",
       "      <td>-70.400208</td>\n",
       "      <td>-565.000305</td>\n",
       "      <td>139.197052</td>\n",
       "      <td>52.216644</td>\n",
       "      <td>298.513367</td>\n",
       "      <td>-554.812134</td>\n",
       "      <td>-305.153015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.111400</td>\n",
       "      <td>-0.237089</td>\n",
       "      <td>-0.539751</td>\n",
       "      <td>...</td>\n",
       "      <td>171.325333</td>\n",
       "      <td>910.947998</td>\n",
       "      <td>-69.889336</td>\n",
       "      <td>-560.900269</td>\n",
       "      <td>138.186935</td>\n",
       "      <td>51.837723</td>\n",
       "      <td>296.347137</td>\n",
       "      <td>-550.786072</td>\n",
       "      <td>-302.938599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>986.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.751877</td>\n",
       "      <td>-0.159403</td>\n",
       "      <td>-0.083471</td>\n",
       "      <td>...</td>\n",
       "      <td>172.558716</td>\n",
       "      <td>917.505859</td>\n",
       "      <td>-70.392471</td>\n",
       "      <td>-564.938171</td>\n",
       "      <td>139.181747</td>\n",
       "      <td>52.210903</td>\n",
       "      <td>298.480530</td>\n",
       "      <td>-554.751221</td>\n",
       "      <td>-305.119446</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.513019</td>\n",
       "      <td>-0.210881</td>\n",
       "      <td>-0.852793</td>\n",
       "      <td>...</td>\n",
       "      <td>171.571793</td>\n",
       "      <td>912.258484</td>\n",
       "      <td>-69.989876</td>\n",
       "      <td>-561.707092</td>\n",
       "      <td>138.385712</td>\n",
       "      <td>51.912292</td>\n",
       "      <td>296.773438</td>\n",
       "      <td>-551.578369</td>\n",
       "      <td>-303.374359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>133.0</td>\n",
       "      <td>1629.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.051877</td>\n",
       "      <td>-0.482063</td>\n",
       "      <td>-0.148663</td>\n",
       "      <td>...</td>\n",
       "      <td>171.583832</td>\n",
       "      <td>912.322449</td>\n",
       "      <td>-69.994781</td>\n",
       "      <td>-561.746460</td>\n",
       "      <td>138.395432</td>\n",
       "      <td>51.915943</td>\n",
       "      <td>296.794281</td>\n",
       "      <td>-551.617126</td>\n",
       "      <td>-303.395721</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1576 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1    2     3     4     5    6         7         8         9  \\\n",
       "0  120.0     0.0  0.0  14.0  18.0  14.0  1.0 -0.470130 -0.494594 -0.253409   \n",
       "1  123.0     0.0  0.0   8.0  22.0  13.0  1.0 -1.111400 -0.237089 -0.539751   \n",
       "2  100.0   986.0  4.0   9.0  32.0  23.0  1.0 -0.751877 -0.159403 -0.083471   \n",
       "3  103.0     0.0  0.0  10.0  31.0  37.0  1.0 -0.513019 -0.210881 -0.852793   \n",
       "4  133.0  1629.0  5.0  10.0  18.0   9.0  1.0 -1.051877 -0.482063 -0.148663   \n",
       "\n",
       "   ...        1566        1567       1568        1569        1570       1571  \\\n",
       "0  ...  172.577667  917.606812 -70.400208 -565.000305  139.197052  52.216644   \n",
       "1  ...  171.325333  910.947998 -69.889336 -560.900269  138.186935  51.837723   \n",
       "2  ...  172.558716  917.505859 -70.392471 -564.938171  139.181747  52.210903   \n",
       "3  ...  171.571793  912.258484 -69.989876 -561.707092  138.385712  51.912292   \n",
       "4  ...  171.583832  912.322449 -69.994781 -561.746460  138.395432  51.915943   \n",
       "\n",
       "         1572        1573        1574  label  \n",
       "0  298.513367 -554.812134 -305.153015      1  \n",
       "1  296.347137 -550.786072 -302.938599      1  \n",
       "2  298.480530 -554.751221 -305.119446      1  \n",
       "3  296.773438 -551.578369 -303.374359      1  \n",
       "4  296.794281 -551.617126 -303.395721      1  \n",
       "\n",
       "[5 rows x 1576 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats=np.array(train_feats)\n",
    "labels=np.array(labels)\n",
    "print(f\"train_feats.shape:{train_feats.shape},labels.shape:{labels.shape}\")\n",
    "print(f\"np.mean(labels):{np.mean(labels)}\")\n",
    "train_feats=pd.DataFrame(train_feats)\n",
    "train_feats['label']=labels\n",
    "train_feats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c74b8d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T13:00:09.334530Z",
     "iopub.status.busy": "2024-04-14T13:00:09.333217Z",
     "iopub.status.idle": "2024-04-14T13:00:09.607485Z",
     "shell.execute_reply": "2024-04-14T13:00:09.605825Z"
    },
    "jupyter": {
     "is_executing": true
    },
    "papermill": {
     "duration": 0.2841,
     "end_time": "2024-04-14T13:00:09.610251",
     "exception": false,
     "start_time": "2024-04-14T13:00:09.326151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_valid_feats = []\n",
    "bert_valid_feats = []\n",
    "graph_valid_feats = []\n",
    "venue_freq = {}\n",
    "for id,person_info in valid_author.items():\n",
    "    for text_id in person_info['papers']:\n",
    "        feat=pid_to_info[text_id]\n",
    "        #['title', 'abstract', 'keywords', 'authors', 'venue', 'year']\n",
    "        try:\n",
    "            publication_age = CURRENT_YEAR - int(feat['year'])       \n",
    "            venue = feat['venue']\n",
    "            if venue in venue_freq:\n",
    "                venue_freq[venue] += 1\n",
    "            else:\n",
    "                venue_freq[venue] = 1\n",
    "                \n",
    "            title_embedding = get_cls_embedding(feat['title'])\n",
    "            abstract_embedding = get_cls_embedding(feat['abstract'])\n",
    "            \n",
    "            bert_valid_features = np.concatenate([title_embedding, abstract_embedding])\n",
    "            \n",
    "            authors = feat['authors']\n",
    "            valid_embeddings = [author_embeddings[author['name']] for author in authors if author['name'] in author_embeddings]\n",
    "            if valid_embeddings:\n",
    "                graph_valid_features = np.mean(valid_embeddings, axis=0)\n",
    "            else:\n",
    "                graph_valid_features = np.zeros(32)\n",
    "\n",
    "            basic_valid_feats.append(\n",
    "                [len(feat['title']),len(feat['abstract']),len(feat['keywords']),len(feat['authors'])\n",
    "                 ,len(feat['venue']),publication_age,venue_freq[venue]]\n",
    "                 )\n",
    "            bert_valid_feats.append(bert_valid_features)\n",
    "            graph_valid_feats.append(graph_valid_features)\n",
    "        except:\n",
    "            basic_valid_feats.append(\n",
    "                [len(feat['title']),len(feat['abstract']),len(feat['keywords']),len(feat['authors'])\n",
    "                 ,len(feat['venue']),24,0]\n",
    "                 )\n",
    "            bert_valid_feats.append([0] * (2 * 768)) \n",
    "            graph_valid_feats.append(np.zeros(32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d386e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并所有特征\n",
    "basic_valid_feats = np.array(basic_valid_feats)\n",
    "bert_valid_feats = np.array(bert_valid_feats)\n",
    "graph_valid_feats = np.array(graph_valid_feats)\n",
    "\n",
    "# 合并所有的特征\n",
    "valid_feats = np.concatenate([basic_valid_feats, bert_valid_feats, graph_valid_feats], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3648dd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_feats.shape:(62229, 1575)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1565</th>\n",
       "      <th>1566</th>\n",
       "      <th>1567</th>\n",
       "      <th>1568</th>\n",
       "      <th>1569</th>\n",
       "      <th>1570</th>\n",
       "      <th>1571</th>\n",
       "      <th>1572</th>\n",
       "      <th>1573</th>\n",
       "      <th>1574</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.031636</td>\n",
       "      <td>-0.218774</td>\n",
       "      <td>0.100672</td>\n",
       "      <td>...</td>\n",
       "      <td>112.741302</td>\n",
       "      <td>37.716206</td>\n",
       "      <td>200.539597</td>\n",
       "      <td>-15.385701</td>\n",
       "      <td>-123.478714</td>\n",
       "      <td>30.421005</td>\n",
       "      <td>11.411760</td>\n",
       "      <td>65.238991</td>\n",
       "      <td>-121.252159</td>\n",
       "      <td>-66.690048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.311767</td>\n",
       "      <td>-0.082533</td>\n",
       "      <td>0.009451</td>\n",
       "      <td>...</td>\n",
       "      <td>37.018524</td>\n",
       "      <td>12.384089</td>\n",
       "      <td>65.847038</td>\n",
       "      <td>-5.051881</td>\n",
       "      <td>-40.544151</td>\n",
       "      <td>9.988714</td>\n",
       "      <td>3.747045</td>\n",
       "      <td>21.421177</td>\n",
       "      <td>-39.813068</td>\n",
       "      <td>-21.897636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.661750</td>\n",
       "      <td>-0.499912</td>\n",
       "      <td>-0.431100</td>\n",
       "      <td>...</td>\n",
       "      <td>4.432458</td>\n",
       "      <td>1.482823</td>\n",
       "      <td>7.884277</td>\n",
       "      <td>-0.604895</td>\n",
       "      <td>-4.854603</td>\n",
       "      <td>1.196013</td>\n",
       "      <td>0.448657</td>\n",
       "      <td>2.564893</td>\n",
       "      <td>-4.767068</td>\n",
       "      <td>-2.621940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109.0</td>\n",
       "      <td>761.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.006846</td>\n",
       "      <td>-0.122845</td>\n",
       "      <td>0.354610</td>\n",
       "      <td>...</td>\n",
       "      <td>2.623996</td>\n",
       "      <td>0.877825</td>\n",
       "      <td>4.667456</td>\n",
       "      <td>-0.358094</td>\n",
       "      <td>-2.873904</td>\n",
       "      <td>0.708033</td>\n",
       "      <td>0.265602</td>\n",
       "      <td>1.518404</td>\n",
       "      <td>-2.822081</td>\n",
       "      <td>-1.552177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.416468</td>\n",
       "      <td>-0.103750</td>\n",
       "      <td>0.049858</td>\n",
       "      <td>...</td>\n",
       "      <td>51.542408</td>\n",
       "      <td>17.242878</td>\n",
       "      <td>91.681503</td>\n",
       "      <td>-7.033946</td>\n",
       "      <td>-56.451271</td>\n",
       "      <td>13.907690</td>\n",
       "      <td>5.217163</td>\n",
       "      <td>29.825581</td>\n",
       "      <td>-55.433342</td>\n",
       "      <td>-30.488977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0       1     2     3     4     5     6         7         8         9     \\\n",
       "0  123.0     0.0   0.0  10.0  79.0   9.0   1.0 -0.031636 -0.218774  0.100672   \n",
       "1  100.0  1060.0   0.0  11.0  36.0   6.0   1.0 -0.311767 -0.082533  0.009451   \n",
       "2   57.0     0.0   0.0   9.0  39.0   8.0   1.0 -0.661750 -0.499912 -0.431100   \n",
       "3  109.0   761.0   7.0   6.0  19.0  23.0   1.0 -0.006846 -0.122845  0.354610   \n",
       "4  108.0  1000.0   5.0  10.0  23.0   4.0   1.0 -0.416468 -0.103750  0.049858   \n",
       "\n",
       "   ...        1565       1566        1567       1568        1569       1570  \\\n",
       "0  ...  112.741302  37.716206  200.539597 -15.385701 -123.478714  30.421005   \n",
       "1  ...   37.018524  12.384089   65.847038  -5.051881  -40.544151   9.988714   \n",
       "2  ...    4.432458   1.482823    7.884277  -0.604895   -4.854603   1.196013   \n",
       "3  ...    2.623996   0.877825    4.667456  -0.358094   -2.873904   0.708033   \n",
       "4  ...   51.542408  17.242878   91.681503  -7.033946  -56.451271  13.907690   \n",
       "\n",
       "        1571       1572        1573       1574  \n",
       "0  11.411760  65.238991 -121.252159 -66.690048  \n",
       "1   3.747045  21.421177  -39.813068 -21.897636  \n",
       "2   0.448657   2.564893   -4.767068  -2.621940  \n",
       "3   0.265602   1.518404   -2.822081  -1.552177  \n",
       "4   5.217163  29.825581  -55.433342 -30.488977  \n",
       "\n",
       "[5 rows x 1575 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_feats=np.array(valid_feats)\n",
    "print(f\"valid_feats.shape:{valid_feats.shape}\")\n",
    "valid_feats=pd.DataFrame(valid_feats)\n",
    "valid_feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c4fd5",
   "metadata": {
    "papermill": {
     "duration": 0.006176,
     "end_time": "2024-04-14T13:00:09.622302",
     "exception": false,
     "start_time": "2024-04-14T13:00:09.616126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 训练10折lightgbm模型."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "989cec24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T13:00:09.636185Z",
     "iopub.status.busy": "2024-04-14T13:00:09.635708Z",
     "iopub.status.idle": "2024-04-14T13:08:45.403174Z",
     "shell.execute_reply": "2024-04-14T13:08:45.401548Z"
    },
    "jupyter": {
     "is_executing": true
    },
    "papermill": {
     "duration": 515.778142,
     "end_time": "2024-04-14T13:08:45.406401",
     "exception": false,
     "start_time": "2024-04-14T13:00:09.628259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "choose_cols=[col for col in valid_feats.columns]\n",
    "\n",
    "def fit_and_predict(model,train_feats=train_feats,test_feats=valid_feats,name=0):\n",
    "    X=train_feats[choose_cols].copy()\n",
    "    y=train_feats[Config.TARGET_NAME].copy()\n",
    "    test_X=test_feats[choose_cols].copy()\n",
    "    oof_pred_pro=np.zeros((len(X),2))\n",
    "    test_pred_pro=np.zeros((Config.num_folds,len(test_X),2))\n",
    "\n",
    "    #10折交叉验证\n",
    "    skf = StratifiedKFold(n_splits=Config.num_folds,random_state=Config.seed, shuffle=True)\n",
    "\n",
    "    for fold, (train_index, valid_index) in (enumerate(skf.split(X, y.astype(str)))):\n",
    "        print(f\"name:{name},fold:{fold}\")\n",
    "\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "\n",
    "        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)],\n",
    "                      callbacks=[log_evaluation(100), early_stopping(100)])\n",
    "\n",
    "        \n",
    "        oof_pred_pro[valid_index]=model.predict_proba(X_valid)\n",
    "        #将数据分批次进行预测.\n",
    "        test_pred_pro[fold]=model.predict_proba(test_X)\n",
    "    print(f\"roc_auc:{roc_auc_score(y.values,oof_pred_pro[:,1])}\")\n",
    "    \n",
    "    return oof_pred_pro,test_pred_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8b78b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:lgb,fold:0\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.746766\n",
      "[200]\tvalid_0's auc: 0.768255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[300]\tvalid_0's auc: 0.778976\n",
      "[400]\tvalid_0's auc: 0.784536\n",
      "[500]\tvalid_0's auc: 0.788728\n",
      "[600]\tvalid_0's auc: 0.791563\n",
      "[700]\tvalid_0's auc: 0.794352\n",
      "[800]\tvalid_0's auc: 0.795522\n",
      "[900]\tvalid_0's auc: 0.797209\n",
      "[1000]\tvalid_0's auc: 0.798226\n",
      "[1100]\tvalid_0's auc: 0.799033\n",
      "[1200]\tvalid_0's auc: 0.800816\n",
      "[1300]\tvalid_0's auc: 0.801872\n",
      "[1400]\tvalid_0's auc: 0.802515\n",
      "[1500]\tvalid_0's auc: 0.803002\n",
      "[1600]\tvalid_0's auc: 0.803416\n",
      "[1700]\tvalid_0's auc: 0.803999\n",
      "[1800]\tvalid_0's auc: 0.804096\n",
      "Early stopping, best iteration is:\n",
      "[1749]\tvalid_0's auc: 0.80446\n",
      "name:lgb,fold:1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.740981\n",
      "[200]\tvalid_0's auc: 0.759394\n",
      "[300]\tvalid_0's auc: 0.767268\n",
      "[400]\tvalid_0's auc: 0.773199\n",
      "[500]\tvalid_0's auc: 0.777207\n",
      "[600]\tvalid_0's auc: 0.780999\n",
      "[700]\tvalid_0's auc: 0.782751\n",
      "[800]\tvalid_0's auc: 0.78372\n",
      "[900]\tvalid_0's auc: 0.785044\n",
      "[1000]\tvalid_0's auc: 0.786337\n",
      "[1100]\tvalid_0's auc: 0.787712\n",
      "[1200]\tvalid_0's auc: 0.788498\n",
      "[1300]\tvalid_0's auc: 0.789215\n",
      "[1400]\tvalid_0's auc: 0.790356\n",
      "[1500]\tvalid_0's auc: 0.791037\n",
      "[1600]\tvalid_0's auc: 0.790776\n",
      "Early stopping, best iteration is:\n",
      "[1528]\tvalid_0's auc: 0.791283\n",
      "name:lgb,fold:2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.740467\n",
      "[200]\tvalid_0's auc: 0.763244\n",
      "[300]\tvalid_0's auc: 0.773344\n",
      "[400]\tvalid_0's auc: 0.782137\n",
      "[500]\tvalid_0's auc: 0.786815\n",
      "[600]\tvalid_0's auc: 0.790272\n",
      "[700]\tvalid_0's auc: 0.792087\n",
      "[800]\tvalid_0's auc: 0.794322\n",
      "[900]\tvalid_0's auc: 0.795359\n",
      "[1000]\tvalid_0's auc: 0.796145\n",
      "[1100]\tvalid_0's auc: 0.796772\n",
      "[1200]\tvalid_0's auc: 0.797183\n",
      "[1300]\tvalid_0's auc: 0.798562\n",
      "[1400]\tvalid_0's auc: 0.799556\n",
      "[1500]\tvalid_0's auc: 0.799928\n",
      "[1600]\tvalid_0's auc: 0.799943\n",
      "[1700]\tvalid_0's auc: 0.800619\n",
      "[1800]\tvalid_0's auc: 0.801116\n",
      "[1900]\tvalid_0's auc: 0.801177\n",
      "Early stopping, best iteration is:\n",
      "[1861]\tvalid_0's auc: 0.801467\n",
      "name:lgb,fold:3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.732166\n",
      "[200]\tvalid_0's auc: 0.751166\n",
      "[300]\tvalid_0's auc: 0.762695\n",
      "[400]\tvalid_0's auc: 0.770483\n",
      "[500]\tvalid_0's auc: 0.773455\n",
      "[600]\tvalid_0's auc: 0.776404\n",
      "[700]\tvalid_0's auc: 0.778331\n",
      "[800]\tvalid_0's auc: 0.780448\n",
      "[900]\tvalid_0's auc: 0.782331\n",
      "[1000]\tvalid_0's auc: 0.783288\n",
      "[1100]\tvalid_0's auc: 0.78437\n",
      "[1200]\tvalid_0's auc: 0.785346\n",
      "[1300]\tvalid_0's auc: 0.78557\n",
      "Early stopping, best iteration is:\n",
      "[1238]\tvalid_0's auc: 0.785886\n",
      "name:lgb,fold:4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.757803\n",
      "[200]\tvalid_0's auc: 0.776223\n",
      "[300]\tvalid_0's auc: 0.784831\n",
      "[400]\tvalid_0's auc: 0.790372\n",
      "[500]\tvalid_0's auc: 0.794137\n",
      "[600]\tvalid_0's auc: 0.796659\n",
      "[700]\tvalid_0's auc: 0.798046\n",
      "[800]\tvalid_0's auc: 0.799855\n",
      "[900]\tvalid_0's auc: 0.801108\n",
      "[1000]\tvalid_0's auc: 0.802826\n",
      "[1100]\tvalid_0's auc: 0.803323\n",
      "[1200]\tvalid_0's auc: 0.804836\n",
      "[1300]\tvalid_0's auc: 0.805729\n",
      "[1400]\tvalid_0's auc: 0.806733\n",
      "[1500]\tvalid_0's auc: 0.807215\n",
      "[1600]\tvalid_0's auc: 0.808922\n",
      "[1700]\tvalid_0's auc: 0.809692\n",
      "[1800]\tvalid_0's auc: 0.809868\n",
      "Early stopping, best iteration is:\n",
      "[1761]\tvalid_0's auc: 0.810064\n",
      "name:lgb,fold:5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.740737\n",
      "[200]\tvalid_0's auc: 0.760226\n",
      "[300]\tvalid_0's auc: 0.772318\n",
      "[400]\tvalid_0's auc: 0.778419\n",
      "[500]\tvalid_0's auc: 0.78326\n",
      "[600]\tvalid_0's auc: 0.785985\n",
      "[700]\tvalid_0's auc: 0.789292\n",
      "[800]\tvalid_0's auc: 0.792313\n",
      "[900]\tvalid_0's auc: 0.794566\n",
      "[1000]\tvalid_0's auc: 0.796253\n",
      "[1100]\tvalid_0's auc: 0.797581\n",
      "[1200]\tvalid_0's auc: 0.798358\n",
      "[1300]\tvalid_0's auc: 0.798502\n",
      "[1400]\tvalid_0's auc: 0.79982\n",
      "[1500]\tvalid_0's auc: 0.800888\n",
      "[1600]\tvalid_0's auc: 0.801719\n",
      "[1700]\tvalid_0's auc: 0.802521\n",
      "Early stopping, best iteration is:\n",
      "[1673]\tvalid_0's auc: 0.802933\n",
      "name:lgb,fold:6\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.740869\n",
      "[200]\tvalid_0's auc: 0.761633\n",
      "[300]\tvalid_0's auc: 0.77102\n",
      "[400]\tvalid_0's auc: 0.775266\n",
      "[500]\tvalid_0's auc: 0.779081\n",
      "[600]\tvalid_0's auc: 0.782068\n",
      "[700]\tvalid_0's auc: 0.783805\n",
      "[800]\tvalid_0's auc: 0.785665\n",
      "[900]\tvalid_0's auc: 0.786737\n",
      "[1000]\tvalid_0's auc: 0.788078\n",
      "[1100]\tvalid_0's auc: 0.79007\n",
      "[1200]\tvalid_0's auc: 0.790368\n",
      "[1300]\tvalid_0's auc: 0.790904\n",
      "[1400]\tvalid_0's auc: 0.792254\n",
      "[1500]\tvalid_0's auc: 0.792864\n",
      "[1600]\tvalid_0's auc: 0.793358\n",
      "[1700]\tvalid_0's auc: 0.793735\n",
      "[1800]\tvalid_0's auc: 0.794315\n",
      "[1900]\tvalid_0's auc: 0.794456\n",
      "Early stopping, best iteration is:\n",
      "[1879]\tvalid_0's auc: 0.794611\n",
      "name:lgb,fold:7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.746153\n",
      "[200]\tvalid_0's auc: 0.766287\n",
      "[300]\tvalid_0's auc: 0.77761\n",
      "[400]\tvalid_0's auc: 0.7852\n",
      "[500]\tvalid_0's auc: 0.788935\n",
      "[600]\tvalid_0's auc: 0.790982\n",
      "[700]\tvalid_0's auc: 0.793706\n",
      "[800]\tvalid_0's auc: 0.795113\n",
      "[900]\tvalid_0's auc: 0.796632\n",
      "[1000]\tvalid_0's auc: 0.797973\n",
      "[1100]\tvalid_0's auc: 0.798332\n",
      "[1200]\tvalid_0's auc: 0.798959\n",
      "[1300]\tvalid_0's auc: 0.800384\n",
      "[1400]\tvalid_0's auc: 0.800668\n",
      "[1500]\tvalid_0's auc: 0.801301\n",
      "[1600]\tvalid_0's auc: 0.801589\n",
      "[1700]\tvalid_0's auc: 0.801904\n",
      "[1800]\tvalid_0's auc: 0.801853\n",
      "Early stopping, best iteration is:\n",
      "[1728]\tvalid_0's auc: 0.80201\n",
      "name:lgb,fold:8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.738031\n",
      "[200]\tvalid_0's auc: 0.759535\n",
      "[300]\tvalid_0's auc: 0.770985\n",
      "[400]\tvalid_0's auc: 0.776623\n",
      "[500]\tvalid_0's auc: 0.780099\n",
      "[600]\tvalid_0's auc: 0.783057\n",
      "[700]\tvalid_0's auc: 0.785767\n",
      "[800]\tvalid_0's auc: 0.787943\n",
      "[900]\tvalid_0's auc: 0.789217\n",
      "[1000]\tvalid_0's auc: 0.791186\n",
      "[1100]\tvalid_0's auc: 0.792693\n",
      "[1200]\tvalid_0's auc: 0.793889\n",
      "[1300]\tvalid_0's auc: 0.795003\n",
      "[1400]\tvalid_0's auc: 0.796019\n",
      "[1500]\tvalid_0's auc: 0.796505\n",
      "[1600]\tvalid_0's auc: 0.796702\n",
      "[1700]\tvalid_0's auc: 0.796934\n",
      "[1800]\tvalid_0's auc: 0.797948\n",
      "[1900]\tvalid_0's auc: 0.798504\n",
      "[2000]\tvalid_0's auc: 0.799139\n",
      "[2100]\tvalid_0's auc: 0.799275\n",
      "Early stopping, best iteration is:\n",
      "[2008]\tvalid_0's auc: 0.799342\n",
      "name:lgb,fold:9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's auc: 0.752605\n",
      "[200]\tvalid_0's auc: 0.774535\n",
      "[300]\tvalid_0's auc: 0.783195\n",
      "[400]\tvalid_0's auc: 0.789704\n",
      "[500]\tvalid_0's auc: 0.792937\n",
      "[600]\tvalid_0's auc: 0.796264\n",
      "[700]\tvalid_0's auc: 0.798934\n",
      "[800]\tvalid_0's auc: 0.801378\n",
      "[900]\tvalid_0's auc: 0.80331\n",
      "[1000]\tvalid_0's auc: 0.804224\n",
      "[1100]\tvalid_0's auc: 0.806297\n",
      "[1200]\tvalid_0's auc: 0.807114\n",
      "[1300]\tvalid_0's auc: 0.807867\n",
      "[1400]\tvalid_0's auc: 0.808782\n",
      "[1500]\tvalid_0's auc: 0.808981\n",
      "[1600]\tvalid_0's auc: 0.809379\n",
      "[1700]\tvalid_0's auc: 0.810108\n",
      "[1800]\tvalid_0's auc: 0.810539\n",
      "[1900]\tvalid_0's auc: 0.810583\n",
      "[2000]\tvalid_0's auc: 0.810865\n",
      "[2100]\tvalid_0's auc: 0.811659\n",
      "[2200]\tvalid_0's auc: 0.812023\n",
      "[2300]\tvalid_0's auc: 0.812242\n",
      "Early stopping, best iteration is:\n",
      "[2277]\tvalid_0's auc: 0.812455\n",
      "roc_auc:0.8003859470412856\n"
     ]
    }
   ],
   "source": [
    "lgb_params={\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"max_depth\": 6,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\":3072,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    \"colsample_bynode\": 0.9,\n",
    "    \"verbose\": -1,\n",
    "    \"random_state\": Config.seed,\n",
    "    \"reg_alpha\": 0.5,\n",
    "    \"reg_lambda\": 15,\n",
    "    \"extra_trees\":True,\n",
    "    'num_leaves':64,\n",
    "    \"verbose\": -1,\n",
    "    \"max_bin\":255,\n",
    "    }\n",
    "\n",
    "lgb_model = LGBMClassifier(**lgb_params)\n",
    "lgb_oof_pred_pro, lgb_test_pred_pro = fit_and_predict(model=lgb_model, train_feats=train_feats, test_feats=valid_feats, name='lgb')\n",
    "\n",
    "test_preds = lgb_test_pred_pro.mean(axis=0)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d98b5fc",
   "metadata": {
    "papermill": {
     "duration": 0.026982,
     "end_time": "2024-04-14T13:08:45.462134",
     "exception": false,
     "start_time": "2024-04-14T13:08:45.435152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 保存为json文件."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66ef8368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-14T13:08:45.518083Z",
     "iopub.status.busy": "2024-04-14T13:08:45.517395Z",
     "iopub.status.idle": "2024-04-14T13:08:45.807668Z",
     "shell.execute_reply": "2024-04-14T13:08:45.806687Z"
    },
    "jupyter": {
     "is_executing": true
    },
    "papermill": {
     "duration": 0.32143,
     "end_time": "2024-04-14T13:08:45.810379",
     "exception": false,
     "start_time": "2024-04-14T13:08:45.488949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnt=0\n",
    "for id,names in submission.items():\n",
    "    for name in names:\n",
    "        submission[id][name]=test_preds[cnt]\n",
    "        cnt+=1\n",
    "with open('test_preds.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(submission, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef53f80f5482e1df",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4794042,
     "sourceId": 8114719,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30684,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 559.868762,
   "end_time": "2024-04-14T13:08:48.270548",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-14T12:59:28.401786",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
